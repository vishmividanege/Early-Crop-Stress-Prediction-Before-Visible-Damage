{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada91102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from torchvision import models  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c31095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf4994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pseudo_labels_with_exg.csv\")\n",
    "\n",
    "file_names = df[\"image\"].tolist()\n",
    "labels = df[\"pseudo_label\"].tolist()\n",
    "\n",
    "base_dir = r\"E:\\Early Crop Stress Prediction Before Visible Damage\\Dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615a2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tif(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        img = src.read(1)\n",
    "\n",
    "    img = cv2.resize(img, (128, 128)).astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0984c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vishm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    rgb = cv2.imread(os.path.join(base_dir, \"RGB\", row[\"image\"]))\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "    rgb = cv2.resize(rgb, (128,128)).astype(np.float32)/255.0\n",
    "\n",
    "    R, G, B = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    exg = 2*G - R - B\n",
    "\n",
    "    ndvi = read_tif(os.path.join(base_dir, \"NDVI\", row[\"image\"]))\n",
    "    vh   = read_tif(os.path.join(base_dir, \"SAR\",\"VH\",row[\"image\"]))\n",
    "    vv   = read_tif(os.path.join(base_dir, \"SAR\",\"VV\",row[\"image\"]))\n",
    "\n",
    "    features.append([\n",
    "        ndvi.mean(),\n",
    "        vh.mean(),\n",
    "        vv.mean(),\n",
    "        exg.mean()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1998be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "y = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f500e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GRADIENT BOOSTING REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       133\n",
      "           1       1.00      1.00      1.00       307\n",
      "\n",
      "    accuracy                           1.00       440\n",
      "   macro avg       1.00      1.00      1.00       440\n",
      "weighted avg       1.00      1.00      1.00       440\n",
      "\n",
      "Confusion Matrix:\n",
      " [[132   1]\n",
      " [  0 307]]\n",
      "Gradient Boosting model saved\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "print(\"=== GRADIENT BOOSTING REPORT ===\")\n",
    "print(classification_report(y_test, gb_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, gb_pred))\n",
    "\n",
    "joblib.dump(gb, \"gb_crop_stress_model.pkl\")\n",
    "print(\"Gradient Boosting model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb12d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropDataset(Dataset):\n",
    "    def __init__(self, base_dir, files, labels):\n",
    "        self.base_dir = base_dir\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        rgb = cv2.imread(os.path.join(self.base_dir,\"RGB\",name))\n",
    "        rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        rgb = cv2.resize(rgb,(128,128)).astype(np.float32)/255.0\n",
    "\n",
    "        ndvi = read_tif(os.path.join(self.base_dir,\"NDVI\",name))[...,None]\n",
    "        vh   = read_tif(os.path.join(self.base_dir,\"SAR\",\"VH\",name))[...,None]\n",
    "        vv   = read_tif(os.path.join(self.base_dir,\"SAR\",\"VV\",name))[...,None]\n",
    "\n",
    "        img = np.concatenate([rgb, ndvi, vh, vv], axis=2)\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "\n",
    "        return img, torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388eb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CropDataset(base_dir, file_names, labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, test_ds = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd31786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetCropStress(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "\n",
    "        self.model.conv1 = nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28684822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNetCropStress().to(device)\n",
    "print(\"Model created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4003519",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f6cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vishm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.2903\n",
      "Epoch 2/10 - Loss: 0.2322\n",
      "Epoch 3/10 - Loss: 0.2028\n",
      "Epoch 4/10 - Loss: 0.1948\n",
      "Epoch 5/10 - Loss: 0.2163\n",
      "Epoch 6/10 - Loss: 0.1842\n",
      "Epoch 7/10 - Loss: 0.1903\n",
      "Epoch 8/10 - Loss: 0.1897\n",
      "Epoch 9/10 - Loss: 0.2012\n",
      "Epoch 10/10 - Loss: 0.1417\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7cde51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNN REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94       139\n",
      "           1       0.99      0.94      0.97       301\n",
      "\n",
      "    accuracy                           0.96       440\n",
      "   macro avg       0.94      0.96      0.95       440\n",
      "weighted avg       0.96      0.96      0.96       440\n",
      "\n",
      "Confusion Matrix:\n",
      " [[137   2]\n",
      " [ 17 284]]\n",
      "CNN model saved\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds, true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds.extend(torch.argmax(outputs,1).cpu().numpy())\n",
    "        true.extend(labels.numpy())\n",
    "\n",
    "print(\"=== CNN REPORT ===\")\n",
    "print(classification_report(true, preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(true, preds))\n",
    "\n",
    "torch.save(model.state_dict(), \"cnn_crop_stress_model.pth\")\n",
    "print(\"CNN model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32b5f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img_name):\n",
    "    rgb = cv2.imread(os.path.join(base_dir,\"RGB\",img_name))\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "    rgb = cv2.resize(rgb,(128,128)).astype(np.float32)/255.0\n",
    "\n",
    "    ndvi = read_tif(os.path.join(base_dir,\"NDVI\",img_name))[...,None]\n",
    "    vh   = read_tif(os.path.join(base_dir,\"SAR\",\"VH\",img_name))[...,None]\n",
    "    vv   = read_tif(os.path.join(base_dir,\"SAR\",\"VV\",img_name))[...,None]\n",
    "\n",
    "    img = np.concatenate([rgb, ndvi, vh, vv], axis=2)\n",
    "    img = torch.tensor(img).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(img)\n",
    "        label = torch.argmax(out,1).item()\n",
    "\n",
    "    return \"Healthy\" if label==0 else \"Stressed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1ccb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Stressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vishm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction:\", predict_image(file_names[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1dc2f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy\n",
      "Train: 1.0\n",
      "Test : 0.9977272727272727\n"
     ]
    }
   ],
   "source": [
    "# Train predictions\n",
    "train_pred = gb.predict(X_train)\n",
    "\n",
    "# Test predictions\n",
    "test_pred = gb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Gradient Boosting Accuracy\")\n",
    "print(\"Train:\", accuracy_score(y_train, train_pred))\n",
    "print(\"Test :\", accuracy_score(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58417a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       533\n",
      "           1       1.00      1.00      1.00      1227\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       133\n",
      "           1       1.00      1.00      1.00       307\n",
      "\n",
      "    accuracy                           1.00       440\n",
      "   macro avg       1.00      1.00      1.00       440\n",
      "weighted avg       1.00      1.00      1.00       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Train Classification Report\")\n",
    "print(classification_report(y_train, train_pred))\n",
    "\n",
    "print(\"Test Classification Report\")\n",
    "print(classification_report(y_test, test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
